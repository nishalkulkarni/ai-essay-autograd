{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce8c3a0",
   "metadata": {},
   "source": [
    "# Classification, Prediction & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a52152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ba88a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>lemma_count</th>\n",
       "      <th>spell_err_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neu_score</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5978</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>4.098039</td>\n",
       "      <td>30</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.086098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5979</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>179</td>\n",
       "      <td>12</td>\n",
       "      <td>4.418994</td>\n",
       "      <td>102</td>\n",
       "      <td>0.089385</td>\n",
       "      <td>0.273743</td>\n",
       "      <td>0.072626</td>\n",
       "      <td>0.162011</td>\n",
       "      <td>0.039106</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.108432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5980</td>\n",
       "      <td>Everyone travels to unfamiliar places. Sometim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97</td>\n",
       "      <td>8</td>\n",
       "      <td>4.164948</td>\n",
       "      <td>67</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.226804</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.195876</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.041446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5981</td>\n",
       "      <td>I believe the features of the cyclist affected...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>3.896552</td>\n",
       "      <td>60</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.218391</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>0.149425</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.030414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5982</td>\n",
       "      <td>The setting effects the cyclist because of the...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134</td>\n",
       "      <td>3</td>\n",
       "      <td>4.126866</td>\n",
       "      <td>73</td>\n",
       "      <td>0.067164</td>\n",
       "      <td>0.231343</td>\n",
       "      <td>0.111940</td>\n",
       "      <td>0.156716</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.071810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>7704</td>\n",
       "      <td>In the story, the setting affected the cyclist...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>4.136364</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287879</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.097250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>7705</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>46</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.085422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>7706</td>\n",
       "      <td>The setting greatly affects the cyclist trying...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>4.159292</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230088</td>\n",
       "      <td>0.061947</td>\n",
       "      <td>0.185841</td>\n",
       "      <td>0.061947</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.082425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>7707</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152</td>\n",
       "      <td>7</td>\n",
       "      <td>4.302632</td>\n",
       "      <td>84</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.217105</td>\n",
       "      <td>0.072368</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0.098684</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.100491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>7708</td>\n",
       "      <td>The features of the setting in “Rough Road Ahe...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>4.277311</td>\n",
       "      <td>79</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>0.151261</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.080284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1726 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                              essay  \\\n",
       "0         5978  The features of the setting affect the cyclist...   \n",
       "1         5979  The features of the setting affected the cycli...   \n",
       "2         5980  Everyone travels to unfamiliar places. Sometim...   \n",
       "3         5981  I believe the features of the cyclist affected...   \n",
       "4         5982  The setting effects the cyclist because of the...   \n",
       "...        ...                                                ...   \n",
       "1721      7704  In the story, the setting affected the cyclist...   \n",
       "1722      7705  The features of the setting affect the cyclist...   \n",
       "1723      7706  The setting greatly affects the cyclist trying...   \n",
       "1724      7707  The features of the setting affected the cycli...   \n",
       "1725      7708  The features of the setting in “Rough Road Ahe...   \n",
       "\n",
       "      domain1_score  word_count  sent_count  avg_word_len  lemma_count  \\\n",
       "0               1.0          51           3      4.098039           30   \n",
       "1               2.0         179          12      4.418994          102   \n",
       "2               1.0          97           8      4.164948           67   \n",
       "3               1.0          87           3      3.896552           60   \n",
       "4               2.0         134           3      4.126866           73   \n",
       "...             ...         ...         ...           ...          ...   \n",
       "1721            2.0          66           6      4.136364           50   \n",
       "1722            1.0          54           3      4.333333           46   \n",
       "1723            2.0         113           5      4.159292           73   \n",
       "1724            2.0         152           7      4.302632           84   \n",
       "1725            3.0         119           5      4.277311           79   \n",
       "\n",
       "      spell_err_count  noun_count  adj_count  verb_count  adv_count  \\\n",
       "0            0.019608    0.294118   0.019608    0.176471   0.000000   \n",
       "1            0.089385    0.273743   0.072626    0.162011   0.039106   \n",
       "2            0.010309    0.226804   0.082474    0.195876   0.113402   \n",
       "3            0.114943    0.218391   0.126437    0.149425   0.034483   \n",
       "4            0.067164    0.231343   0.111940    0.156716   0.059701   \n",
       "...               ...         ...        ...         ...        ...   \n",
       "1721         0.000000    0.287879   0.075758    0.212121   0.015152   \n",
       "1722         0.037037    0.277778   0.092593    0.185185   0.129630   \n",
       "1723         0.000000    0.230088   0.061947    0.185841   0.061947   \n",
       "1724         0.013158    0.217105   0.072368    0.197368   0.098684   \n",
       "1725         0.000000    0.285714   0.067227    0.151261   0.050420   \n",
       "\n",
       "      neg_score  pos_score  neu_score  cosine_similarity  \n",
       "0         0.094      0.000      0.906           0.086098  \n",
       "1         0.098      0.043      0.860           0.108432  \n",
       "2         0.151      0.116      0.733           0.041446  \n",
       "3         0.067      0.108      0.825           0.030414  \n",
       "4         0.120      0.029      0.851           0.071810  \n",
       "...         ...        ...        ...                ...  \n",
       "1721      0.101      0.064      0.834           0.097250  \n",
       "1722      0.141      0.042      0.817           0.085422  \n",
       "1723      0.148      0.000      0.852           0.082425  \n",
       "1724      0.057      0.052      0.891           0.100491  \n",
       "1725      0.000      0.093      0.907           0.080284  \n",
       "\n",
       "[1726 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('features/features_set_3.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98898f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,3:]\n",
    "y=data.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52792405",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test = train_test_split(X ,y, test_size=0.2 , random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c566d0",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "### What is Random Forest?\n",
    "Random Forest is a powerful and versatile supervised machine learning algorithm that grows and combines multiple decision trees to create a “forest”.  A decision tree is another type of algorithm used to classify data. In very simple terms, it is like a flowchart that draws a clear pathway to a decision or outcome; it starts at a single point and then branches off into two or more directions, with each branch of the decision tree offering different possible outcomes.\n",
    "\n",
    "### How does it work?\n",
    "Random Forest grows multiple decision trees which are merged together for a more accurate prediction.\n",
    "\n",
    "The logic behind the Random Forest model is that multiple uncorrelated models (the individual decision trees) perform much better as a group than they do alone. When using Random Forest for classification, each tree gives a classification or a “vote.” The forest chooses the classification with the majority of the “votes.” When using Random Forest for regression, the forest picks the average of the outputs of all trees.\n",
    "\n",
    "### Advantages\n",
    "1. Very easy to use.\n",
    "2. Random Forest is much more efficient than a single Decision Tree while performing analysis on a large database.\n",
    "3. Random forests have a very good accuracy.\n",
    "4. They are versatile (can be used for regression or classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fcab3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced_subsample')\n",
    "rf_params = {'n_estimators':list(range(20,200,10)),\n",
    "                'max_depth':list(range(2,14,1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6b6e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = sklearn.metrics.make_scorer(sklearn.metrics.f1_score, average = 'macro')\n",
    "rf_random=GridSearchCV(estimator = rf, param_grid  = rf_params, cv = 5, verbose=2,  n_jobs = 2, scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af108920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(class_weight='balanced_subsample'),\n",
       "             n_jobs=2,\n",
       "             param_grid={'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
       "                         'n_estimators': [20, 30, 40, 50, 60, 70, 80, 90, 100,\n",
       "                                          110, 120, 130, 140, 150, 160, 170,\n",
       "                                          180, 190]},\n",
       "             scoring=make_scorer(f1_score, average=macro), verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1529f797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', max_depth=10,\n",
       "                       n_estimators=120, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_final = RandomForestClassifier(random_state=0, n_estimators=rf_random.best_params_['n_estimators'], max_depth=rf_random.best_params_['max_depth'],class_weight='balanced_subsample')\n",
    "rf_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76399166",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = rf_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9a7087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000         0\n",
      "         1.0      0.821     0.716     0.765       141\n",
      "         2.0      0.642     0.705     0.672       122\n",
      "         3.0      0.741     0.723     0.732        83\n",
      "\n",
      "    accuracy                          0.714       346\n",
      "   macro avg      0.551     0.536     0.542       346\n",
      "weighted avg      0.739     0.714     0.724       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(X_pred,y_test,digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bf0da66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, X_pred)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41e0a872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7138728323699421\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, X_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa7626",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb67926",
   "metadata": {},
   "source": [
    "### What is XGBoost?\n",
    "\n",
    "XGBoost is one of the most popular machine learning algorithm these days. Regardless of the type of prediction task at hand; regression or classification. XGBoost is well known to provide better solutions than other machine learning algorithms. In fact, since its inception, it has become the \"state-of-the-art” machine learning algorithm to deal with structured data.\n",
    "\n",
    "XGBoost belongs to a family of boosting algorithms and uses the gradient boosting (GBM) framework at its core. It is an optimized distributed gradient boosting library.\n",
    "\n",
    "### Boosting\n",
    "Boosting is a sequential technique which works on the principle of an ensemble. It combines a set of weak learners and delivers improved prediction accuracy. At any instant t, the model outcomes are weighed based on the outcomes of previous instant t-1. The outcomes predicted correctly are given a lower weight and the ones miss-classified are weighted higher. A weak learner is one which is slightly better than random guessing. \n",
    "\n",
    "\n",
    "### Advantages of XGBoost:\n",
    "\n",
    "1. It is comparatively faster than other ensemble classifiers\n",
    "2. The code XGBoost algorithm is parallelizable and hence can harness the power of multi-core GPUs.\n",
    "3. It has a wide range of tuning parameters (cross-validation, regularization, user-defined objective functions, missing values, tree parameters, scikit-learn compatible API).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e6e1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(tree_method = \"exact\", predictor = \"cpu_predictor\",\n",
    "                            objective = \"multi:softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae4fdc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "               \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "               \"max_depth\": [2, 4, 7, 10],\n",
    "               \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "               \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "               \"reg_alpha\": [0, 0.5, 1],\n",
    "               \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "               \"min_child_weight\": [1, 3, 5, 7],\n",
    "               \"n_estimators\": [100, 250, 500, 1000]}\n",
    "# subsample: Denotes the subsample ratio of columns for each split, in each level.\n",
    "# colsample_bytree: Denotes the fraction of columns to be randomly samples for each tree.\n",
    "# gamma: Gamma specifies the minimum loss reduction required to make a split.\n",
    "# reg_alpha: Lasso L1 regularization\n",
    "# reg_lambda: Ridge L2 reguralarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RandomizedSearchCV Object\n",
    "xgb_rscv = RandomizedSearchCV(xgb_clf, param_distributions = parameters, scoring = \"f1_micro\",\n",
    "                             cv = 10, verbose = 3, random_state = 40 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c24c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[08:41:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.2s\n",
      "[08:41:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.1s\n",
      "[08:41:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.2s\n",
      "[08:41:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.2s\n",
      "[08:41:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.2s\n",
      "[08:42:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.2s\n",
      "[08:42:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.4s\n",
      "[08:42:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.2s\n",
      "[08:42:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.2s\n",
      "[08:42:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.2s\n",
      "[08:42:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4; total time=   0.2s\n",
      "[08:42:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4; total time=   0.1s\n",
      "[08:42:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4; total time=   0.2s\n",
      "[08:42:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4; total time=   0.1s\n",
      "[08:42:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4; total time=   0.2s\n",
      "[08:42:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4; total time=   0.1s\n",
      "[08:42:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4; total time=   0.2s\n",
      "[08:42:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4; total time=   0.1s\n",
      "[08:42:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4; total time=   0.3s\n",
      "[08:42:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4; total time=   0.1s\n",
      "[08:42:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2; total time=   0.3s\n",
      "[08:42:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2; total time=   0.6s\n",
      "[08:42:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2; total time=   0.3s\n",
      "[08:42:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2; total time=   0.3s\n",
      "[08:42:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2; total time=   0.3s\n",
      "[08:42:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2; total time=   0.3s\n",
      "[08:42:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2; total time=   0.3s\n",
      "[08:42:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2; total time=   0.3s\n",
      "[08:42:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2; total time=   0.3s\n",
      "[08:42:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2; total time=   0.3s\n",
      "[08:42:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.2s\n",
      "[08:42:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.2s\n",
      "[08:42:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.2s\n",
      "[08:42:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.2s\n",
      "[08:42:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.2s\n",
      "[08:42:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.2s\n",
      "[08:42:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.2s\n",
      "[08:42:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.2s\n",
      "[08:42:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.2s\n",
      "[08:42:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.2s\n",
      "[08:42:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5; total time=   1.2s\n",
      "[08:42:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5; total time=   1.2s\n",
      "[08:42:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5; total time=   1.2s\n",
      "[08:42:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5; total time=   1.2s\n",
      "[08:42:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5; total time=   1.3s\n",
      "[08:42:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5; total time=   1.3s\n",
      "[08:42:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5; total time=   1.2s\n",
      "[08:42:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5; total time=   1.2s\n",
      "[08:42:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5; total time=   1.2s\n",
      "[08:42:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5; total time=   1.3s\n",
      "[08:42:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   0.3s\n",
      "[08:42:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   0.3s\n",
      "[08:42:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   0.4s\n",
      "[08:42:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   0.6s\n",
      "[08:42:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   0.3s\n",
      "[08:42:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   0.3s\n",
      "[08:42:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   0.4s\n",
      "[08:42:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   0.4s\n",
      "[08:42:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   0.4s\n",
      "[08:42:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7; total time=   0.3s\n",
      "[08:42:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   0.7s\n",
      "[08:42:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   0.8s\n",
      "[08:42:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   0.7s\n",
      "[08:42:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   0.9s\n",
      "[08:42:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   0.7s\n",
      "[08:42:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   0.7s\n",
      "[08:42:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   0.7s\n",
      "[08:42:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   0.7s\n",
      "[08:42:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   0.7s\n",
      "[08:42:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   0.8s\n",
      "[08:42:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4; total time=   3.2s\n",
      "[08:42:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4; total time=   3.5s\n",
      "[08:42:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4; total time=   4.4s\n",
      "[08:42:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4; total time=   3.2s\n",
      "[08:42:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4; total time=   3.5s\n",
      "[08:42:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4; total time=   3.1s\n",
      "[08:42:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4; total time=   2.9s\n",
      "[08:42:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4; total time=   2.8s\n",
      "[08:42:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4; total time=   2.9s\n",
      "[08:43:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4; total time=   2.9s\n",
      "[08:43:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   1.2s\n",
      "[08:43:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   1.1s\n",
      "[08:43:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   1.2s\n",
      "[08:43:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   0.9s\n",
      "[08:43:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   0.9s\n",
      "[08:43:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   1.0s\n",
      "[08:43:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   1.2s\n",
      "[08:43:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   1.8s\n",
      "[08:43:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   1.0s\n",
      "[08:43:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7; total time=   1.1s\n",
      "[08:43:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4; total time=   0.5s\n",
      "[08:43:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4; total time=   0.7s\n",
      "[08:43:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4; total time=   1.2s\n",
      "[08:43:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4; total time=   0.6s\n",
      "[08:43:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4; total time=   1.2s\n",
      "[08:43:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4; total time=   0.5s\n",
      "[08:43:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4; total time=   0.6s\n",
      "[08:43:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4; total time=   0.5s\n",
      "[08:43:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4; total time=   0.5s\n",
      "[08:43:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4; total time=   0.6s\n",
      "[08:43:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "model_xgboost = xgb_rscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60e6cbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:43:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1.0,\n",
       "              enable_categorical=False, gamma=1.5, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=12, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=0.6,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_final = XGBClassifier(random_state=0, \n",
    "                          n_estimators=xgb_rscv.best_params_['n_estimators'], \n",
    "                          max_depth=xgb_rscv.best_params_['max_depth'],\n",
    "                          learning_rate=xgb_rscv.best_params_['learning_rate'],\n",
    "                          gamma=xgb_rscv.best_params_['gamma'],\n",
    "                          colsample_bytree=xgb_rscv.best_params_['colsample_bytree'],\n",
    "                          subsample=xgb_rscv.best_params_['subsample'],\n",
    "                          reg_alpha=xgb_rscv.best_params_['reg_alpha'],\n",
    "                          reg_lambda=xgb_rscv.best_params_['reg_lambda'],\n",
    "                          min_child_weight=xgb_rscv.best_params_['min_child_weight'])\n",
    "xgb_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07011f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acf44109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.250     1.000     0.400         2\n",
      "         1.0      0.789     0.688     0.735       141\n",
      "         2.0      0.604     0.643     0.623       126\n",
      "         3.0      0.679     0.714     0.696        77\n",
      "\n",
      "    accuracy                          0.679       346\n",
      "   macro avg      0.581     0.761     0.614       346\n",
      "weighted avg      0.694     0.679     0.684       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_pred,y_test,digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5e798a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm1 = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0ffb871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6791907514450867"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016bd82f",
   "metadata": {},
   "source": [
    "## Support Vector Classifier\n",
    "\n",
    "### What is a Support Vector Machine (SVM)?\n",
    "A support vector machine (SVM) is a supervised machine learning model that uses classification algorithms for two-group classification problems. After giving an SVM model sets of labeled training data for each category, they’re able to categorize new text.\n",
    "\n",
    "Compared to newer algorithms like neural networks, they have two main advantages: higher speed and better performance with a limited number of samples (in the thousands). This makes the algorithm very suitable for text classification problems, where it’s common to have access to a dataset of at most a couple of thousands of tagged samples.\n",
    "\n",
    "### How do SVMs work?\n",
    "A support vector machine takes data points and outputs the hyperplane (which in two dimensions it’s simply a line) that best separates the tags. This line is the decision boundary: anything that falls to one side of it we will classify as blue, and anything that falls to the other as red.\n",
    "\n",
    "<img src=\"hyperplane.png\" />\n",
    "\n",
    "### Advantages\n",
    "1. SVMs can give results at a higher speed and better accuracy with lesser number of samples.\n",
    "2. The SVM provides a very useful technique within it known as kernel and by the application of associated kernel function we can solve any complex problem.\n",
    "3. SVM generally do not suffer condition of overfitting and performs well when there is a clear indication of separation between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c28a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_Train = sc_X.fit_transform(X_train)\n",
    "X_Test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3de852fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_Train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d192ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Pred = classifier.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a51a888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm2 = confusion_matrix(y_test, Y_Pred)\n",
    "sns.heatmap(cm2, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2da8a219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6734104046242775"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, Y_Pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62dae5",
   "metadata": {},
   "source": [
    "## Extreme Learning Machine (ELM)\n",
    "\n",
    "### What is ELM?\n",
    "Extreme learning machines are feed-forward neural networks for classification, regression, clustering, sparse approximation, compression and feature learning with a single layer or multiple layers of hidden nodes, where the parameters of hidden nodes (not just the weights connecting inputs to hidden nodes) need not be tuned. These hidden nodes can be randomly assigned and never updated (i.e. they are random projection but with nonlinear transforms), or can be inherited from their ancestors without being changed. In most cases, the output weights of hidden nodes are usually learned in a single step, which essentially amounts to learning a linear model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53818935",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "### What is Linear Regression?\n",
    "Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. One variable is considered to be an explanatory variable, and the other is considered to be a dependent variable. For example, a modeler might want to relate the weights of individuals to their heights using a linear regression model.\n",
    "\n",
    "### How does it work?\n",
    "A linear regression line has an equation of the form Y = a + bX, where X is the explanatory variable and Y is the dependent variable. The slope of the line is b, and a is the intercept (the value of y when x = 0). \n",
    "### Advantages\n",
    "1. Linear Regression is a very simple algorithm that can be implemented very easily to give satisfactory results.\n",
    "2. Linear regression fits linearly seperable datasets almost perfectly and is often used to find the nature of the relationship between variables.\n",
    "3. Overfitting can be reduced by regularization. <strong>Overfitting</strong> is a situation that arises when a machine learning model fits a dataset very closely and hence captures the noisy data as well.This negatively impacts the performance of model and reduces its accuracy on the test set. <strong>Regularization</strong> is a technique that can be easily implemented and is capable of effectively reducing the complexity of a function so as to reduce the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d59e4a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73fd94bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination is:  0.5317174721103257\n",
      "Model intercept:  -6.054430506751153\n",
      "Slope:  [ 2.96547935e-03  8.89948015e-03  2.84538504e-01  1.12440048e-02\n",
      "  3.72476033e-01  2.17551740e-01 -1.90805075e-01  4.97894323e-01\n",
      "  1.41310959e-01  5.90243090e+00  5.62982668e+00  4.90937084e+00\n",
      "  4.70038035e+00]\n"
     ]
    }
   ],
   "source": [
    "    r_sq = model.score(X_train, y_train)\n",
    "    print('Coefficient of determination is: ', r_sq)\n",
    "    print('Model intercept: ', model.intercept_)\n",
    "    print(\"Slope: \", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "394484f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:  [1, 2, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 0, 2, 0, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 2, 1, 1, 3, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 0, 2, 1, 2, 0, 1, 2, 2, 0, 2, 2, 1, 1, 2, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 1, 2, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 0, 1, 1, 1, 2, 1, 3, 2, 3, 3, 1, 0, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 0, 1, 1, 2, 2, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 3, 1, 1, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 0, 1, 1, 1, 2, 1, 1, 2, 3, 0, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 3, 1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "y_pred = list(map(int, model.predict(X_test)))\n",
    "print(\"Predicted values: \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c44b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.3204\n",
      "Variance score: 0.5100\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error: %.4f\" % np.mean((model.predict(X_test) - y_test) ** 2))\n",
    "print('Variance score: %.4f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "024f4b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45375722543352603"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ba8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
