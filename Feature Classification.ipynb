{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce8c3a0",
   "metadata": {},
   "source": [
    "## Feature Classification\n",
    "\n",
    "In this notebook we...\n",
    "\n",
    "### Novelty\n",
    "...\n",
    "\n",
    "\n",
    "#### REFRENCES:\n",
    "1. Mahana, M., Johns, M., & Apte, A. (2012). Automated essay grading using machine learning. Mach. Learn. Session, Stanford University.\n",
    "\n",
    "2. Suresh, A., & Jha, M. (2018). Automated essay grading using natural language processing and support vector machine. International Journal of Computing and Technology, 5(2), 18-21.\n",
    "\n",
    "3. Rokade, A., Patil, B., Rajani, S., Revandkar, S., & Shedge, R. (2018, April). Automated Grading System Using Natural Language Processing. In 2018 Second International Conference on Inventive Communication and Computational Technologies (ICICCT) (pp. 1123-1127). IEEE.\n",
    "\n",
    "4. Song, S., & Zhao, J. (2013). Automated essay scoring using machine learning. Stanford University.\n",
    "\n",
    "5. Kakkonen, T., Myller, N., & Sutinen, E. (2006). Applying Part-of-Seech Enhanced LSA to Automatic Essay Grading. arXiv preprint cs/0610118."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a52152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinavgorantla/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.1.36ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ba88a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>lemma_count</th>\n",
       "      <th>spell_err_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neu_score</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350</td>\n",
       "      <td>16</td>\n",
       "      <td>4.237143</td>\n",
       "      <td>162</td>\n",
       "      <td>0.045714</td>\n",
       "      <td>0.237143</td>\n",
       "      <td>0.051429</td>\n",
       "      <td>0.211429</td>\n",
       "      <td>0.068571</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.090943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>423</td>\n",
       "      <td>20</td>\n",
       "      <td>4.312057</td>\n",
       "      <td>185</td>\n",
       "      <td>0.061466</td>\n",
       "      <td>0.252955</td>\n",
       "      <td>0.044917</td>\n",
       "      <td>0.200946</td>\n",
       "      <td>0.044917</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>283</td>\n",
       "      <td>14</td>\n",
       "      <td>4.342756</td>\n",
       "      <td>145</td>\n",
       "      <td>0.031802</td>\n",
       "      <td>0.289753</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>0.183746</td>\n",
       "      <td>0.056537</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.069262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>530</td>\n",
       "      <td>27</td>\n",
       "      <td>4.813208</td>\n",
       "      <td>236</td>\n",
       "      <td>0.122642</td>\n",
       "      <td>0.335849</td>\n",
       "      <td>0.079245</td>\n",
       "      <td>0.183019</td>\n",
       "      <td>0.054717</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.056878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>473</td>\n",
       "      <td>30</td>\n",
       "      <td>4.334038</td>\n",
       "      <td>190</td>\n",
       "      <td>0.035941</td>\n",
       "      <td>0.241015</td>\n",
       "      <td>0.067653</td>\n",
       "      <td>0.190275</td>\n",
       "      <td>0.076110</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.071470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>3190</td>\n",
       "      <td>I believe that they should not be pulled off o...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>368</td>\n",
       "      <td>28</td>\n",
       "      <td>4.105978</td>\n",
       "      <td>152</td>\n",
       "      <td>0.024457</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>0.190217</td>\n",
       "      <td>0.081522</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.221566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>3191</td>\n",
       "      <td>When have you ever went into a library and fou...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>610</td>\n",
       "      <td>36</td>\n",
       "      <td>4.013115</td>\n",
       "      <td>199</td>\n",
       "      <td>0.031148</td>\n",
       "      <td>0.178689</td>\n",
       "      <td>0.054098</td>\n",
       "      <td>0.254098</td>\n",
       "      <td>0.068852</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.212200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3192</td>\n",
       "      <td>When I go to a library I @MONTH1 find some stu...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>196</td>\n",
       "      <td>11</td>\n",
       "      <td>4.076531</td>\n",
       "      <td>102</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.134513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>3193</td>\n",
       "      <td>Certain people beleive that offensive books, m...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>382</td>\n",
       "      <td>19</td>\n",
       "      <td>4.526178</td>\n",
       "      <td>141</td>\n",
       "      <td>0.031414</td>\n",
       "      <td>0.225131</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.206806</td>\n",
       "      <td>0.078534</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.206831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3194</td>\n",
       "      <td>Katherine Paterson said ' If I have the right ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>433</td>\n",
       "      <td>13</td>\n",
       "      <td>4.094688</td>\n",
       "      <td>145</td>\n",
       "      <td>0.034642</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>0.090069</td>\n",
       "      <td>0.182448</td>\n",
       "      <td>0.096998</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.211123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                              essay  \\\n",
       "0            1  Dear local newspaper, I think effects computer...   \n",
       "1            2  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2            3  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3            4  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4            5  Dear @LOCATION1, I know having computers has a...   \n",
       "...        ...                                                ...   \n",
       "1995      3190  I believe that they should not be pulled off o...   \n",
       "1996      3191  When have you ever went into a library and fou...   \n",
       "1997      3192  When I go to a library I @MONTH1 find some stu...   \n",
       "1998      3193  Certain people beleive that offensive books, m...   \n",
       "1999      3194  Katherine Paterson said ' If I have the right ...   \n",
       "\n",
       "      domain1_score  word_count  sent_count  avg_word_len  lemma_count  \\\n",
       "0               8.0         350          16      4.237143          162   \n",
       "1               9.0         423          20      4.312057          185   \n",
       "2               7.0         283          14      4.342756          145   \n",
       "3              10.0         530          27      4.813208          236   \n",
       "4               8.0         473          30      4.334038          190   \n",
       "...             ...         ...         ...           ...          ...   \n",
       "1995            4.0         368          28      4.105978          152   \n",
       "1996            4.0         610          36      4.013115          199   \n",
       "1997            3.0         196          11      4.076531          102   \n",
       "1998            3.0         382          19      4.526178          141   \n",
       "1999            3.0         433          13      4.094688          145   \n",
       "\n",
       "      spell_err_count  noun_count  adj_count  verb_count  adv_count  \\\n",
       "0            0.045714    0.237143   0.051429    0.211429   0.068571   \n",
       "1            0.061466    0.252955   0.044917    0.200946   0.044917   \n",
       "2            0.031802    0.289753   0.070671    0.183746   0.056537   \n",
       "3            0.122642    0.335849   0.079245    0.183019   0.054717   \n",
       "4            0.035941    0.241015   0.067653    0.190275   0.076110   \n",
       "...               ...         ...        ...         ...        ...   \n",
       "1995         0.024457    0.195652   0.097826    0.190217   0.081522   \n",
       "1996         0.031148    0.178689   0.054098    0.254098   0.068852   \n",
       "1997         0.045918    0.183673   0.102041    0.250000   0.051020   \n",
       "1998         0.031414    0.225131   0.083770    0.206806   0.078534   \n",
       "1999         0.034642    0.175520   0.090069    0.182448   0.096998   \n",
       "\n",
       "      neg_score  pos_score  neu_score  cosine_similarity  \n",
       "0         0.000      0.170      0.830           0.090943  \n",
       "1         0.014      0.219      0.766           0.049000  \n",
       "2         0.045      0.197      0.759           0.069262  \n",
       "3         0.008      0.152      0.840           0.056878  \n",
       "4         0.026      0.096      0.879           0.071470  \n",
       "...         ...        ...        ...                ...  \n",
       "1995      0.121      0.092      0.786           0.221566  \n",
       "1996      0.144      0.051      0.805           0.212200  \n",
       "1997      0.156      0.107      0.737           0.134513  \n",
       "1998      0.128      0.074      0.798           0.206831  \n",
       "1999      0.077      0.059      0.864           0.211123  \n",
       "\n",
       "[2000 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('features.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98898f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,3:]\n",
    "y=data.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52792405",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test = train_test_split(X ,y, test_size=0.2 , random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c566d0",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fcab3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced_subsample')\n",
    "rf_params = {'n_estimators':list(range(20,200,10)),\n",
    "                'max_depth':list(range(2,14,1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6b6e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = sklearn.metrics.make_scorer(sklearn.metrics.f1_score, average = 'macro')\n",
    "rf_random=GridSearchCV(estimator = rf, param_grid  = rf_params, cv = 5, verbose=2,  n_jobs = 2, scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af108920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "[CV] END .......................max_depth=2, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=2, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=2, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=2, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=2, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=2, n_estimators=30; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=30; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=30; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=30; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=2, n_estimators=40; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=40; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=40; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=40; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=40; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=2, n_estimators=60; total time=   0.3s\n",
      "[CV] END .......................max_depth=2, n_estimators=60; total time=   0.3s\n",
      "[CV] END .......................max_depth=2, n_estimators=60; total time=   0.3s\n",
      "[CV] END .......................max_depth=2, n_estimators=60; total time=   0.3s\n",
      "[CV] END .......................max_depth=2, n_estimators=60; total time=   0.4s\n",
      "[CV] END .......................max_depth=2, n_estimators=70; total time=   0.4s\n",
      "[CV] END .......................max_depth=2, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=2, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=2, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=2, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=2, n_estimators=80; total time=   0.4s\n",
      "[CV] END .......................max_depth=2, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=2, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=2, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=2, n_estimators=80; total time=   0.4s\n",
      "[CV] END .......................max_depth=2, n_estimators=90; total time=   0.4s\n",
      "[CV] END .......................max_depth=2, n_estimators=90; total time=   0.4s\n",
      "[CV] END .......................max_depth=2, n_estimators=90; total time=   0.4s\n",
      "[CV] END .......................max_depth=2, n_estimators=90; total time=   0.4s\n",
      "[CV] END .......................max_depth=2, n_estimators=90; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=110; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=110; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=110; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=120; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=120; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=120; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=120; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=120; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=130; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=130; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=130; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=130; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=130; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=140; total time=   0.6s\n",
      "[CV] END ......................max_depth=2, n_estimators=140; total time=   0.7s\n",
      "[CV] END ......................max_depth=2, n_estimators=140; total time=   0.7s\n",
      "[CV] END ......................max_depth=2, n_estimators=140; total time=   0.7s\n",
      "[CV] END ......................max_depth=2, n_estimators=140; total time=   0.7s\n",
      "[CV] END ......................max_depth=2, n_estimators=150; total time=   0.7s\n",
      "[CV] END ......................max_depth=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=150; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=160; total time=   0.7s\n",
      "[CV] END ......................max_depth=2, n_estimators=160; total time=   0.7s\n",
      "[CV] END ......................max_depth=2, n_estimators=160; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=160; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=160; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=170; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=170; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=180; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=180; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=180; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=180; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=180; total time=   0.4s\n",
      "[CV] END ......................max_depth=2, n_estimators=190; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=190; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=190; total time=   0.5s\n",
      "[CV] END ......................max_depth=2, n_estimators=190; total time=   0.5s\n",
      "[CV] END .......................max_depth=3, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=20; total time=   0.1s\n",
      "[CV] END ......................max_depth=2, n_estimators=190; total time=   0.6s\n",
      "[CV] END .......................max_depth=3, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......................max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=80; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=3, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=90; total time=   0.2s\n",
      "[CV] END .......................max_depth=3, n_estimators=90; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=110; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=110; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=110; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=120; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=120; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=120; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=130; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=130; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=130; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=130; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=130; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=140; total time=   0.6s\n",
      "[CV] END ......................max_depth=3, n_estimators=140; total time=   0.7s\n",
      "[CV] END ......................max_depth=3, n_estimators=140; total time=   0.6s\n",
      "[CV] END ......................max_depth=3, n_estimators=140; total time=   0.6s\n",
      "[CV] END ......................max_depth=3, n_estimators=140; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=150; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=150; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=150; total time=   0.3s\n",
      "[CV] END ......................max_depth=3, n_estimators=160; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=160; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=160; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=160; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=160; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=170; total time=   0.4s\n",
      "[CV] END ......................max_depth=3, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=170; total time=   0.6s\n",
      "[CV] END ......................max_depth=3, n_estimators=180; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=180; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=180; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=180; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=180; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=190; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=190; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=190; total time=   0.5s\n",
      "[CV] END ......................max_depth=3, n_estimators=190; total time=   0.5s\n",
      "[CV] END .......................max_depth=4, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=20; total time=   0.1s\n",
      "[CV] END ......................max_depth=3, n_estimators=190; total time=   0.5s\n",
      "[CV] END .......................max_depth=4, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......................max_depth=4, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=4, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=4, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=4, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=4, n_estimators=80; total time=   0.2s\n",
      "[CV] END .......................max_depth=4, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=4, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=4, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=4, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=4, n_estimators=90; total time=   0.3s\n",
      "[CV] END ......................max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV] END ......................max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV] END ......................max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV] END ......................max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV] END ......................max_depth=4, n_estimators=110; total time=   0.3s\n",
      "[CV] END ......................max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=120; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=130; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=130; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=130; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=130; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=130; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=140; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=140; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=140; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=140; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=140; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=150; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=150; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=150; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=150; total time=   0.4s\n",
      "[CV] END ......................max_depth=4, n_estimators=150; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=160; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=180; total time=   0.6s\n",
      "[CV] END ......................max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=180; total time=   0.5s\n",
      "[CV] END ......................max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV] END ......................max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV] END ......................max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV] END ......................max_depth=4, n_estimators=190; total time=   0.6s\n",
      "[CV] END .......................max_depth=5, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=20; total time=   0.1s\n",
      "[CV] END ......................max_depth=4, n_estimators=190; total time=   0.7s\n",
      "[CV] END .......................max_depth=5, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=5, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=5, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=5, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=5, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=5, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=5, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=5, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=5, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=5, n_estimators=80; total time=   0.4s\n",
      "[CV] END .......................max_depth=5, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=5, n_estimators=80; total time=   0.4s\n",
      "[CV] END .......................max_depth=5, n_estimators=90; total time=   0.4s\n",
      "[CV] END .......................max_depth=5, n_estimators=90; total time=   0.4s\n",
      "[CV] END .......................max_depth=5, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=5, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=5, n_estimators=90; total time=   0.3s\n",
      "[CV] END ......................max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=5, n_estimators=110; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=110; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=110; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=110; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=110; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=120; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=120; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=120; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=120; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END ......................max_depth=5, n_estimators=130; total time=   0.7s\n",
      "[CV] END ......................max_depth=5, n_estimators=130; total time=   0.6s\n",
      "[CV] END ......................max_depth=5, n_estimators=130; total time=   0.5s\n",
      "[CV] END ......................max_depth=5, n_estimators=130; total time=   0.5s\n",
      "[CV] END ......................max_depth=5, n_estimators=130; total time=   0.5s\n",
      "[CV] END ......................max_depth=5, n_estimators=140; total time=   0.8s\n",
      "[CV] END ......................max_depth=5, n_estimators=140; total time=   0.7s\n",
      "[CV] END ......................max_depth=5, n_estimators=140; total time=   0.6s\n",
      "[CV] END ......................max_depth=5, n_estimators=140; total time=   0.6s\n",
      "[CV] END ......................max_depth=5, n_estimators=140; total time=   0.6s\n",
      "[CV] END ......................max_depth=5, n_estimators=150; total time=   0.6s\n",
      "[CV] END ......................max_depth=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV] END ......................max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV] END ......................max_depth=5, n_estimators=150; total time=   0.5s\n",
      "[CV] END ......................max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=160; total time=   0.4s\n",
      "[CV] END ......................max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=5, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=5, n_estimators=180; total time=   0.6s\n",
      "[CV] END ......................max_depth=5, n_estimators=180; total time=   0.6s\n",
      "[CV] END ......................max_depth=5, n_estimators=180; total time=   0.6s\n",
      "[CV] END ......................max_depth=5, n_estimators=180; total time=   0.7s\n",
      "[CV] END ......................max_depth=5, n_estimators=180; total time=   0.6s\n",
      "[CV] END ......................max_depth=5, n_estimators=190; total time=   0.7s\n",
      "[CV] END ......................max_depth=5, n_estimators=190; total time=   0.7s\n",
      "[CV] END ......................max_depth=5, n_estimators=190; total time=   0.7s\n",
      "[CV] END ......................max_depth=5, n_estimators=190; total time=   0.7s\n",
      "[CV] END .......................max_depth=6, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=6, n_estimators=20; total time=   0.1s\n",
      "[CV] END ......................max_depth=5, n_estimators=190; total time=   0.7s\n",
      "[CV] END .......................max_depth=6, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=6, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=6, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=6, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=6, n_estimators=30; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=30; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=6, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=6, n_estimators=40; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=40; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=6, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=6, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=80; total time=   0.2s\n",
      "[CV] END .......................max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=6, n_estimators=90; total time=   0.3s\n",
      "[CV] END ......................max_depth=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END ......................max_depth=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END ......................max_depth=6, n_estimators=100; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=100; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=120; total time=   0.7s\n",
      "[CV] END ......................max_depth=6, n_estimators=120; total time=   0.7s\n",
      "[CV] END ......................max_depth=6, n_estimators=120; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=120; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=120; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=130; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=130; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=130; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=130; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=130; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=140; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=140; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=140; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=140; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=140; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=150; total time=   0.7s\n",
      "[CV] END ......................max_depth=6, n_estimators=150; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=150; total time=   0.7s\n",
      "[CV] END ......................max_depth=6, n_estimators=150; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=150; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=160; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=160; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=160; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=160; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=170; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=170; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=170; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=180; total time=   0.6s\n",
      "[CV] END ......................max_depth=6, n_estimators=180; total time=   0.5s\n",
      "[CV] END ......................max_depth=6, n_estimators=180; total time=   0.7s\n",
      "[CV] END ......................max_depth=6, n_estimators=180; total time=   0.8s\n",
      "[CV] END ......................max_depth=6, n_estimators=180; total time=   0.8s\n",
      "[CV] END ......................max_depth=6, n_estimators=190; total time=   0.8s\n",
      "[CV] END ......................max_depth=6, n_estimators=190; total time=   0.8s\n",
      "[CV] END ......................max_depth=6, n_estimators=190; total time=   0.8s\n",
      "[CV] END ......................max_depth=6, n_estimators=190; total time=   1.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=20; total time=   0.1s\n",
      "[CV] END ......................max_depth=6, n_estimators=190; total time=   1.0s\n",
      "[CV] END .......................max_depth=7, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=30; total time=   0.2s\n",
      "[CV] END .......................max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=7, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=7, n_estimators=50; total time=   0.3s\n",
      "[CV] END .......................max_depth=7, n_estimators=60; total time=   0.4s\n",
      "[CV] END .......................max_depth=7, n_estimators=60; total time=   0.3s\n",
      "[CV] END .......................max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=7, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=7, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=7, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=7, n_estimators=80; total time=   0.4s\n",
      "[CV] END .......................max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=7, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=7, n_estimators=80; total time=   0.4s\n",
      "[CV] END .......................max_depth=7, n_estimators=80; total time=   0.4s\n",
      "[CV] END .......................max_depth=7, n_estimators=90; total time=   0.5s\n",
      "[CV] END .......................max_depth=7, n_estimators=90; total time=   0.4s\n",
      "[CV] END .......................max_depth=7, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=7, n_estimators=90; total time=   0.4s\n",
      "[CV] END .......................max_depth=7, n_estimators=90; total time=   0.4s\n",
      "[CV] END ......................max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=7, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=7, n_estimators=100; total time=   0.5s\n",
      "[CV] END ......................max_depth=7, n_estimators=100; total time=   0.6s\n",
      "[CV] END ......................max_depth=7, n_estimators=100; total time=   0.5s\n",
      "[CV] END ......................max_depth=7, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=7, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=7, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=7, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=7, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=7, n_estimators=120; total time=   0.6s\n",
      "[CV] END ......................max_depth=7, n_estimators=120; total time=   0.6s\n",
      "[CV] END ......................max_depth=7, n_estimators=120; total time=   0.6s\n",
      "[CV] END ......................max_depth=7, n_estimators=120; total time=   0.5s\n",
      "[CV] END ......................max_depth=7, n_estimators=120; total time=   0.5s\n",
      "[CV] END ......................max_depth=7, n_estimators=130; total time=   0.6s\n",
      "[CV] END ......................max_depth=7, n_estimators=130; total time=   0.6s\n",
      "[CV] END ......................max_depth=7, n_estimators=130; total time=   0.6s\n",
      "[CV] END ......................max_depth=7, n_estimators=130; total time=   0.7s\n",
      "[CV] END ......................max_depth=7, n_estimators=130; total time=   0.7s\n",
      "[CV] END ......................max_depth=7, n_estimators=140; total time=   0.7s\n",
      "[CV] END ......................max_depth=7, n_estimators=140; total time=   0.8s\n",
      "[CV] END ......................max_depth=7, n_estimators=140; total time=   0.8s\n",
      "[CV] END ......................max_depth=7, n_estimators=140; total time=   0.8s\n",
      "[CV] END ......................max_depth=7, n_estimators=140; total time=   0.9s\n",
      "[CV] END ......................max_depth=7, n_estimators=150; total time=   1.0s\n",
      "[CV] END ......................max_depth=7, n_estimators=150; total time=   1.0s\n",
      "[CV] END ......................max_depth=7, n_estimators=150; total time=   0.8s\n",
      "[CV] END ......................max_depth=7, n_estimators=150; total time=   0.9s\n",
      "[CV] END ......................max_depth=7, n_estimators=150; total time=   1.0s\n",
      "[CV] END ......................max_depth=7, n_estimators=160; total time=   0.8s\n",
      "[CV] END ......................max_depth=7, n_estimators=160; total time=   0.8s\n",
      "[CV] END ......................max_depth=7, n_estimators=160; total time=   0.6s\n",
      "[CV] END ......................max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV] END ......................max_depth=7, n_estimators=160; total time=   0.5s\n",
      "[CV] END ......................max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV] END ......................max_depth=7, n_estimators=170; total time=   0.8s\n",
      "[CV] END ......................max_depth=7, n_estimators=170; total time=   0.7s\n",
      "[CV] END ......................max_depth=7, n_estimators=170; total time=   0.9s\n",
      "[CV] END ......................max_depth=7, n_estimators=170; total time=   1.1s\n",
      "[CV] END ......................max_depth=7, n_estimators=180; total time=   0.9s\n",
      "[CV] END ......................max_depth=7, n_estimators=180; total time=   0.7s\n",
      "[CV] END ......................max_depth=7, n_estimators=180; total time=   0.8s\n",
      "[CV] END ......................max_depth=7, n_estimators=180; total time=   0.9s\n",
      "[CV] END ......................max_depth=7, n_estimators=180; total time=   0.9s\n",
      "[CV] END ......................max_depth=7, n_estimators=190; total time=   0.8s\n",
      "[CV] END ......................max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV] END ......................max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV] END ......................max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV] END .......................max_depth=8, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=8, n_estimators=20; total time=   0.1s\n",
      "[CV] END ......................max_depth=7, n_estimators=190; total time=   0.6s\n",
      "[CV] END .......................max_depth=8, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=8, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=8, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=8, n_estimators=30; total time=   0.1s\n",
      "[CV] END .......................max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=8, n_estimators=40; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=40; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=40; total time=   0.1s\n",
      "[CV] END .......................max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=60; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=70; total time=   0.2s\n",
      "[CV] END .......................max_depth=8, n_estimators=70; total time=   0.3s\n",
      "[CV] END .......................max_depth=8, n_estimators=80; total time=   0.4s\n",
      "[CV] END .......................max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=8, n_estimators=80; total time=   0.3s\n",
      "[CV] END .......................max_depth=8, n_estimators=80; total time=   0.4s\n",
      "[CV] END .......................max_depth=8, n_estimators=80; total time=   0.4s\n",
      "[CV] END .......................max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV] END .......................max_depth=8, n_estimators=90; total time=   0.3s\n",
      "[CV] END ......................max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......................max_depth=8, n_estimators=100; total time=   0.5s\n",
      "[CV] END ......................max_depth=8, n_estimators=100; total time=   0.6s\n",
      "[CV] END ......................max_depth=8, n_estimators=110; total time=   0.7s\n",
      "[CV] END ......................max_depth=8, n_estimators=110; total time=   0.6s\n",
      "[CV] END ......................max_depth=8, n_estimators=110; total time=   0.4s\n",
      "[CV] END ......................max_depth=8, n_estimators=110; total time=   0.5s\n",
      "[CV] END ......................max_depth=8, n_estimators=110; total time=   0.6s\n",
      "[CV] END ......................max_depth=8, n_estimators=120; total time=   0.6s\n",
      "[CV] END ......................max_depth=8, n_estimators=120; total time=   0.6s\n",
      "[CV] END ......................max_depth=8, n_estimators=120; total time=   0.7s\n",
      "[CV] END ......................max_depth=8, n_estimators=120; total time=   0.7s\n",
      "[CV] END ......................max_depth=8, n_estimators=120; total time=   0.7s\n",
      "[CV] END ......................max_depth=8, n_estimators=130; total time=   0.7s\n",
      "[CV] END ......................max_depth=8, n_estimators=130; total time=   0.7s\n",
      "[CV] END ......................max_depth=8, n_estimators=130; total time=   0.7s\n",
      "[CV] END ......................max_depth=8, n_estimators=130; total time=   0.8s\n",
      "[CV] END ......................max_depth=8, n_estimators=130; total time=   0.7s\n",
      "[CV] END ......................max_depth=8, n_estimators=140; total time=   0.7s\n",
      "[CV] END ......................max_depth=8, n_estimators=140; total time=   0.8s\n",
      "[CV] END ......................max_depth=8, n_estimators=140; total time=   0.8s\n",
      "[CV] END ......................max_depth=8, n_estimators=140; total time=   0.9s\n",
      "[CV] END ......................max_depth=8, n_estimators=140; total time=   0.9s\n",
      "[CV] END ......................max_depth=8, n_estimators=150; total time=   1.0s\n",
      "[CV] END ......................max_depth=8, n_estimators=150; total time=   0.9s\n",
      "[CV] END ......................max_depth=8, n_estimators=150; total time=   0.8s\n",
      "[CV] END ......................max_depth=8, n_estimators=150; total time=   0.7s\n",
      "[CV] END ......................max_depth=8, n_estimators=150; total time=   0.8s\n",
      "[CV] END ......................max_depth=8, n_estimators=160; total time=   1.1s\n",
      "[CV] END ......................max_depth=8, n_estimators=160; total time=   1.1s\n",
      "[CV] END ......................max_depth=8, n_estimators=160; total time=   1.0s\n",
      "[CV] END ......................max_depth=8, n_estimators=160; total time=   1.0s\n",
      "[CV] END ......................max_depth=8, n_estimators=160; total time=   1.0s\n",
      "[CV] END ......................max_depth=8, n_estimators=170; total time=   1.0s\n",
      "[CV] END ......................max_depth=8, n_estimators=170; total time=   1.1s\n",
      "[CV] END ......................max_depth=8, n_estimators=170; total time=   1.1s\n",
      "[CV] END ......................max_depth=8, n_estimators=170; total time=   1.1s\n",
      "[CV] END ......................max_depth=8, n_estimators=170; total time=   1.1s\n",
      "[CV] END ......................max_depth=8, n_estimators=180; total time=   1.1s\n",
      "[CV] END ......................max_depth=8, n_estimators=180; total time=   1.1s\n",
      "[CV] END ......................max_depth=8, n_estimators=180; total time=   1.1s\n",
      "[CV] END ......................max_depth=8, n_estimators=180; total time=   1.1s\n",
      "[CV] END ......................max_depth=8, n_estimators=180; total time=   1.1s\n",
      "[CV] END ......................max_depth=8, n_estimators=190; total time=   1.2s\n",
      "[CV] END ......................max_depth=8, n_estimators=190; total time=   1.3s\n",
      "[CV] END ......................max_depth=8, n_estimators=190; total time=   1.5s\n",
      "[CV] END ......................max_depth=8, n_estimators=190; total time=   1.3s\n",
      "[CV] END .......................max_depth=9, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=9, n_estimators=20; total time=   0.2s\n",
      "[CV] END .......................max_depth=9, n_estimators=20; total time=   0.1s\n",
      "[CV] END .......................max_depth=9, n_estimators=20; total time=   0.1s\n",
      "[CV] END ......................max_depth=8, n_estimators=190; total time=   1.3s\n",
      "[CV] END .......................max_depth=9, n_estimators=20; total time=   0.2s\n",
      "[CV] END .......................max_depth=9, n_estimators=30; total time=   0.3s\n",
      "[CV] END .......................max_depth=9, n_estimators=30; total time=   0.3s\n",
      "[CV] END .......................max_depth=9, n_estimators=30; total time=   0.3s\n",
      "[CV] END .......................max_depth=9, n_estimators=30; total time=   0.3s\n",
      "[CV] END .......................max_depth=9, n_estimators=30; total time=   0.3s\n",
      "[CV] END .......................max_depth=9, n_estimators=40; total time=   0.4s\n",
      "[CV] END .......................max_depth=9, n_estimators=40; total time=   0.3s\n",
      "[CV] END .......................max_depth=9, n_estimators=40; total time=   0.3s\n",
      "[CV] END .......................max_depth=9, n_estimators=40; total time=   0.3s\n",
      "[CV] END .......................max_depth=9, n_estimators=40; total time=   0.4s\n",
      "[CV] END .......................max_depth=9, n_estimators=50; total time=   0.8s\n",
      "[CV] END .......................max_depth=9, n_estimators=50; total time=   0.7s\n",
      "[CV] END .......................max_depth=9, n_estimators=50; total time=   0.3s\n",
      "[CV] END .......................max_depth=9, n_estimators=50; total time=   0.4s\n",
      "[CV] END .......................max_depth=9, n_estimators=50; total time=   0.6s\n",
      "[CV] END .......................max_depth=9, n_estimators=60; total time=   0.8s\n",
      "[CV] END .......................max_depth=9, n_estimators=60; total time=   0.8s\n",
      "[CV] END .......................max_depth=9, n_estimators=60; total time=   0.7s\n",
      "[CV] END .......................max_depth=9, n_estimators=60; total time=   0.6s\n",
      "[CV] END .......................max_depth=9, n_estimators=60; total time=   0.5s\n",
      "[CV] END .......................max_depth=9, n_estimators=70; total time=   0.7s\n",
      "[CV] END .......................max_depth=9, n_estimators=70; total time=   0.6s\n",
      "[CV] END .......................max_depth=9, n_estimators=70; total time=   0.6s\n",
      "[CV] END .......................max_depth=9, n_estimators=70; total time=   0.6s\n",
      "[CV] END .......................max_depth=9, n_estimators=70; total time=   0.6s\n",
      "[CV] END .......................max_depth=9, n_estimators=80; total time=   0.7s\n",
      "[CV] END .......................max_depth=9, n_estimators=80; total time=   0.9s\n",
      "[CV] END .......................max_depth=9, n_estimators=80; total time=   0.8s\n",
      "[CV] END .......................max_depth=9, n_estimators=80; total time=   0.5s\n",
      "[CV] END .......................max_depth=9, n_estimators=80; total time=   0.5s\n",
      "[CV] END .......................max_depth=9, n_estimators=90; total time=   0.6s\n",
      "[CV] END .......................max_depth=9, n_estimators=90; total time=   0.6s\n",
      "[CV] END .......................max_depth=9, n_estimators=90; total time=   0.6s\n",
      "[CV] END .......................max_depth=9, n_estimators=90; total time=   0.6s\n",
      "[CV] END .......................max_depth=9, n_estimators=90; total time=   0.6s\n",
      "[CV] END ......................max_depth=9, n_estimators=100; total time=   0.8s\n",
      "[CV] END ......................max_depth=9, n_estimators=100; total time=   0.8s\n",
      "[CV] END ......................max_depth=9, n_estimators=100; total time=   0.7s\n",
      "[CV] END ......................max_depth=9, n_estimators=100; total time=   0.6s\n",
      "[CV] END ......................max_depth=9, n_estimators=100; total time=   0.6s\n",
      "[CV] END ......................max_depth=9, n_estimators=110; total time=   0.7s\n",
      "[CV] END ......................max_depth=9, n_estimators=110; total time=   0.8s\n",
      "[CV] END ......................max_depth=9, n_estimators=110; total time=   0.7s\n",
      "[CV] END ......................max_depth=9, n_estimators=110; total time=   0.7s\n",
      "[CV] END ......................max_depth=9, n_estimators=110; total time=   0.8s\n",
      "[CV] END ......................max_depth=9, n_estimators=120; total time=   0.8s\n",
      "[CV] END ......................max_depth=9, n_estimators=120; total time=   0.8s\n",
      "[CV] END ......................max_depth=9, n_estimators=120; total time=   0.8s\n",
      "[CV] END ......................max_depth=9, n_estimators=120; total time=   0.7s\n",
      "[CV] END ......................max_depth=9, n_estimators=120; total time=   0.7s\n",
      "[CV] END ......................max_depth=9, n_estimators=130; total time=   0.8s\n",
      "[CV] END ......................max_depth=9, n_estimators=130; total time=   0.8s\n",
      "[CV] END ......................max_depth=9, n_estimators=130; total time=   0.9s\n",
      "[CV] END ......................max_depth=9, n_estimators=130; total time=   0.9s\n",
      "[CV] END ......................max_depth=9, n_estimators=130; total time=   0.8s\n",
      "[CV] END ......................max_depth=9, n_estimators=140; total time=   0.9s\n",
      "[CV] END ......................max_depth=9, n_estimators=140; total time=   0.9s\n",
      "[CV] END ......................max_depth=9, n_estimators=140; total time=   0.9s\n",
      "[CV] END ......................max_depth=9, n_estimators=140; total time=   1.0s\n",
      "[CV] END ......................max_depth=9, n_estimators=140; total time=   0.9s\n",
      "[CV] END ......................max_depth=9, n_estimators=150; total time=   0.9s\n",
      "[CV] END ......................max_depth=9, n_estimators=150; total time=   1.0s\n",
      "[CV] END ......................max_depth=9, n_estimators=150; total time=   1.0s\n",
      "[CV] END ......................max_depth=9, n_estimators=150; total time=   1.0s\n",
      "[CV] END ......................max_depth=9, n_estimators=150; total time=   0.9s\n",
      "[CV] END ......................max_depth=9, n_estimators=160; total time=   1.0s\n",
      "[CV] END ......................max_depth=9, n_estimators=160; total time=   1.1s\n",
      "[CV] END ......................max_depth=9, n_estimators=160; total time=   1.1s\n",
      "[CV] END ......................max_depth=9, n_estimators=160; total time=   1.0s\n",
      "[CV] END ......................max_depth=9, n_estimators=160; total time=   1.0s\n",
      "[CV] END ......................max_depth=9, n_estimators=170; total time=   1.1s\n",
      "[CV] END ......................max_depth=9, n_estimators=170; total time=   1.1s\n",
      "[CV] END ......................max_depth=9, n_estimators=170; total time=   1.3s\n",
      "[CV] END ......................max_depth=9, n_estimators=170; total time=   1.2s\n",
      "[CV] END ......................max_depth=9, n_estimators=170; total time=   1.1s\n",
      "[CV] END ......................max_depth=9, n_estimators=180; total time=   1.1s\n",
      "[CV] END ......................max_depth=9, n_estimators=180; total time=   1.2s\n",
      "[CV] END ......................max_depth=9, n_estimators=180; total time=   1.3s\n",
      "[CV] END ......................max_depth=9, n_estimators=180; total time=   1.2s\n",
      "[CV] END ......................max_depth=9, n_estimators=180; total time=   1.1s\n",
      "[CV] END ......................max_depth=9, n_estimators=190; total time=   1.1s\n",
      "[CV] END ......................max_depth=9, n_estimators=190; total time=   1.1s\n",
      "[CV] END ......................max_depth=9, n_estimators=190; total time=   1.3s\n",
      "[CV] END ......................max_depth=9, n_estimators=190; total time=   1.3s\n",
      "[CV] END ......................max_depth=10, n_estimators=20; total time=   0.1s\n",
      "[CV] END ......................max_depth=10, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=10, n_estimators=20; total time=   0.1s\n",
      "[CV] END ......................max_depth=10, n_estimators=20; total time=   0.1s\n",
      "[CV] END ......................max_depth=10, n_estimators=20; total time=   0.1s\n",
      "[CV] END ......................max_depth=9, n_estimators=190; total time=   1.2s\n",
      "[CV] END ......................max_depth=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=10, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=10, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=10, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=10, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=10, n_estimators=40; total time=   0.2s\n",
      "[CV] END ......................max_depth=10, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ......................max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ......................max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ......................max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ......................max_depth=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END ......................max_depth=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END ......................max_depth=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END ......................max_depth=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END ......................max_depth=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END ......................max_depth=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END ......................max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV] END ......................max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV] END ......................max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV] END ......................max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV] END ......................max_depth=10, n_estimators=70; total time=   0.4s\n",
      "[CV] END ......................max_depth=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END ......................max_depth=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END ......................max_depth=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END ......................max_depth=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END ......................max_depth=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END ......................max_depth=10, n_estimators=90; total time=   0.6s\n",
      "[CV] END ......................max_depth=10, n_estimators=90; total time=   0.6s\n",
      "[CV] END ......................max_depth=10, n_estimators=90; total time=   0.6s\n",
      "[CV] END ......................max_depth=10, n_estimators=90; total time=   0.6s\n",
      "[CV] END ......................max_depth=10, n_estimators=90; total time=   0.6s\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END .....................max_depth=10, n_estimators=110; total time=   0.7s\n",
      "[CV] END .....................max_depth=10, n_estimators=110; total time=   0.7s\n",
      "[CV] END .....................max_depth=10, n_estimators=110; total time=   0.7s\n",
      "[CV] END .....................max_depth=10, n_estimators=110; total time=   0.7s\n",
      "[CV] END .....................max_depth=10, n_estimators=110; total time=   0.7s\n",
      "[CV] END .....................max_depth=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END .....................max_depth=10, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=10, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=10, n_estimators=130; total time=   1.0s\n",
      "[CV] END .....................max_depth=10, n_estimators=130; total time=   1.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=130; total time=   0.9s\n",
      "[CV] END .....................max_depth=10, n_estimators=130; total time=   0.9s\n",
      "[CV] END .....................max_depth=10, n_estimators=130; total time=   0.9s\n",
      "[CV] END .....................max_depth=10, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=10, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=10, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=10, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=10, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=10, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=160; total time=   1.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=160; total time=   1.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=160; total time=   1.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=160; total time=   1.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=160; total time=   1.1s\n",
      "[CV] END .....................max_depth=10, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=10, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=10, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=10, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=10, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=10, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=10, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=10, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=10, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=10, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=10, n_estimators=190; total time=   1.4s\n",
      "[CV] END .....................max_depth=10, n_estimators=190; total time=   1.3s\n",
      "[CV] END .....................max_depth=10, n_estimators=190; total time=   1.3s\n",
      "[CV] END .....................max_depth=10, n_estimators=190; total time=   1.3s\n",
      "[CV] END ......................max_depth=11, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=11, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=11, n_estimators=20; total time=   0.2s\n",
      "[CV] END .....................max_depth=10, n_estimators=190; total time=   1.4s\n",
      "[CV] END ......................max_depth=11, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=11, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=11, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=11, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=11, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=11, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=11, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=11, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=11, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=11, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=11, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=11, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=11, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=11, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=11, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=11, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=11, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=11, n_estimators=60; total time=   0.4s\n",
      "[CV] END ......................max_depth=11, n_estimators=60; total time=   0.4s\n",
      "[CV] END ......................max_depth=11, n_estimators=60; total time=   0.5s\n",
      "[CV] END ......................max_depth=11, n_estimators=60; total time=   0.5s\n",
      "[CV] END ......................max_depth=11, n_estimators=60; total time=   0.4s\n",
      "[CV] END ......................max_depth=11, n_estimators=70; total time=   0.6s\n",
      "[CV] END ......................max_depth=11, n_estimators=70; total time=   0.5s\n",
      "[CV] END ......................max_depth=11, n_estimators=70; total time=   0.7s\n",
      "[CV] END ......................max_depth=11, n_estimators=70; total time=   0.7s\n",
      "[CV] END ......................max_depth=11, n_estimators=70; total time=   0.5s\n",
      "[CV] END ......................max_depth=11, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=11, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=11, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=11, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=11, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=11, n_estimators=90; total time=   0.7s\n",
      "[CV] END ......................max_depth=11, n_estimators=90; total time=   0.7s\n",
      "[CV] END ......................max_depth=11, n_estimators=90; total time=   0.7s\n",
      "[CV] END ......................max_depth=11, n_estimators=90; total time=   0.7s\n",
      "[CV] END ......................max_depth=11, n_estimators=90; total time=   0.6s\n",
      "[CV] END .....................max_depth=11, n_estimators=100; total time=   0.7s\n",
      "[CV] END .....................max_depth=11, n_estimators=100; total time=   0.7s\n",
      "[CV] END .....................max_depth=11, n_estimators=100; total time=   0.7s\n",
      "[CV] END .....................max_depth=11, n_estimators=100; total time=   0.7s\n",
      "[CV] END .....................max_depth=11, n_estimators=100; total time=   0.7s\n",
      "[CV] END .....................max_depth=11, n_estimators=110; total time=   0.8s\n",
      "[CV] END .....................max_depth=11, n_estimators=110; total time=   0.8s\n",
      "[CV] END .....................max_depth=11, n_estimators=110; total time=   0.8s\n",
      "[CV] END .....................max_depth=11, n_estimators=110; total time=   0.8s\n",
      "[CV] END .....................max_depth=11, n_estimators=110; total time=   0.8s\n",
      "[CV] END .....................max_depth=11, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=11, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=11, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=11, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=11, n_estimators=120; total time=   1.0s\n",
      "[CV] END .....................max_depth=11, n_estimators=130; total time=   1.0s\n",
      "[CV] END .....................max_depth=11, n_estimators=130; total time=   1.0s\n",
      "[CV] END .....................max_depth=11, n_estimators=130; total time=   0.9s\n",
      "[CV] END .....................max_depth=11, n_estimators=130; total time=   0.9s\n",
      "[CV] END .....................max_depth=11, n_estimators=130; total time=   0.9s\n",
      "[CV] END .....................max_depth=11, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=11, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=11, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=11, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=11, n_estimators=140; total time=   1.1s\n",
      "[CV] END .....................max_depth=11, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=11, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=11, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=11, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=11, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=11, n_estimators=160; total time=   1.1s\n",
      "[CV] END .....................max_depth=11, n_estimators=160; total time=   1.1s\n",
      "[CV] END .....................max_depth=11, n_estimators=160; total time=   1.1s\n",
      "[CV] END .....................max_depth=11, n_estimators=160; total time=   1.1s\n",
      "[CV] END .....................max_depth=11, n_estimators=160; total time=   1.1s\n",
      "[CV] END .....................max_depth=11, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=11, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=11, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=11, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=11, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=11, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=11, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=11, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=11, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=11, n_estimators=180; total time=   1.2s\n",
      "[CV] END .....................max_depth=11, n_estimators=190; total time=   1.3s\n",
      "[CV] END .....................max_depth=11, n_estimators=190; total time=   1.3s\n",
      "[CV] END .....................max_depth=11, n_estimators=190; total time=   1.4s\n",
      "[CV] END .....................max_depth=11, n_estimators=190; total time=   1.3s\n",
      "[CV] END ......................max_depth=12, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=12, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=12, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=12, n_estimators=20; total time=   0.2s\n",
      "[CV] END .....................max_depth=11, n_estimators=190; total time=   1.4s\n",
      "[CV] END ......................max_depth=12, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=12, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=12, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=12, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=12, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=12, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=12, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=12, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=12, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=12, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=12, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=12, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=12, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=12, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=12, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=12, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=12, n_estimators=60; total time=   0.5s\n",
      "[CV] END ......................max_depth=12, n_estimators=60; total time=   0.5s\n",
      "[CV] END ......................max_depth=12, n_estimators=60; total time=   0.5s\n",
      "[CV] END ......................max_depth=12, n_estimators=60; total time=   0.5s\n",
      "[CV] END ......................max_depth=12, n_estimators=60; total time=   0.5s\n",
      "[CV] END ......................max_depth=12, n_estimators=70; total time=   0.5s\n",
      "[CV] END ......................max_depth=12, n_estimators=70; total time=   0.5s\n",
      "[CV] END ......................max_depth=12, n_estimators=70; total time=   0.6s\n",
      "[CV] END ......................max_depth=12, n_estimators=70; total time=   0.5s\n",
      "[CV] END ......................max_depth=12, n_estimators=70; total time=   0.5s\n",
      "[CV] END ......................max_depth=12, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=12, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=12, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=12, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=12, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=12, n_estimators=90; total time=   0.7s\n",
      "[CV] END ......................max_depth=12, n_estimators=90; total time=   0.7s\n",
      "[CV] END ......................max_depth=12, n_estimators=90; total time=   0.7s\n",
      "[CV] END ......................max_depth=12, n_estimators=90; total time=   0.7s\n",
      "[CV] END ......................max_depth=12, n_estimators=90; total time=   0.7s\n",
      "[CV] END .....................max_depth=12, n_estimators=100; total time=   0.8s\n",
      "[CV] END .....................max_depth=12, n_estimators=100; total time=   0.7s\n",
      "[CV] END .....................max_depth=12, n_estimators=100; total time=   0.7s\n",
      "[CV] END .....................max_depth=12, n_estimators=100; total time=   0.8s\n",
      "[CV] END .....................max_depth=12, n_estimators=100; total time=   0.7s\n",
      "[CV] END .....................max_depth=12, n_estimators=110; total time=   0.8s\n",
      "[CV] END .....................max_depth=12, n_estimators=110; total time=   0.8s\n",
      "[CV] END .....................max_depth=12, n_estimators=110; total time=   0.8s\n",
      "[CV] END .....................max_depth=12, n_estimators=110; total time=   0.8s\n",
      "[CV] END .....................max_depth=12, n_estimators=110; total time=   0.8s\n",
      "[CV] END .....................max_depth=12, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=12, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=12, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=12, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=12, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=12, n_estimators=130; total time=   0.9s\n",
      "[CV] END .....................max_depth=12, n_estimators=130; total time=   0.9s\n",
      "[CV] END .....................max_depth=12, n_estimators=130; total time=   0.9s\n",
      "[CV] END .....................max_depth=12, n_estimators=130; total time=   0.9s\n",
      "[CV] END .....................max_depth=12, n_estimators=130; total time=   1.0s\n",
      "[CV] END .....................max_depth=12, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=12, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=12, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=12, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=12, n_estimators=140; total time=   1.0s\n",
      "[CV] END .....................max_depth=12, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=12, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=12, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=12, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=12, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=12, n_estimators=160; total time=   1.1s\n",
      "[CV] END .....................max_depth=12, n_estimators=160; total time=   1.1s\n",
      "[CV] END .....................max_depth=12, n_estimators=160; total time=   1.2s\n",
      "[CV] END .....................max_depth=12, n_estimators=160; total time=   1.2s\n",
      "[CV] END .....................max_depth=12, n_estimators=160; total time=   1.2s\n",
      "[CV] END .....................max_depth=12, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=12, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=12, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=12, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=12, n_estimators=170; total time=   1.2s\n",
      "[CV] END .....................max_depth=12, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=12, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=12, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=12, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=12, n_estimators=180; total time=   1.3s\n",
      "[CV] END .....................max_depth=12, n_estimators=190; total time=   1.4s\n",
      "[CV] END .....................max_depth=12, n_estimators=190; total time=   1.4s\n",
      "[CV] END .....................max_depth=12, n_estimators=190; total time=   1.4s\n",
      "[CV] END .....................max_depth=12, n_estimators=190; total time=   1.4s\n",
      "[CV] END ......................max_depth=13, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=13, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=13, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=13, n_estimators=20; total time=   0.2s\n",
      "[CV] END .....................max_depth=12, n_estimators=190; total time=   1.4s\n",
      "[CV] END ......................max_depth=13, n_estimators=20; total time=   0.2s\n",
      "[CV] END ......................max_depth=13, n_estimators=30; total time=   0.3s\n",
      "[CV] END ......................max_depth=13, n_estimators=30; total time=   0.3s\n",
      "[CV] END ......................max_depth=13, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=13, n_estimators=30; total time=   0.2s\n",
      "[CV] END ......................max_depth=13, n_estimators=30; total time=   0.3s\n",
      "[CV] END ......................max_depth=13, n_estimators=40; total time=   0.4s\n",
      "[CV] END ......................max_depth=13, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=13, n_estimators=40; total time=   0.3s\n",
      "[CV] END ......................max_depth=13, n_estimators=40; total time=   0.4s\n",
      "[CV] END ......................max_depth=13, n_estimators=40; total time=   0.5s\n",
      "[CV] END ......................max_depth=13, n_estimators=50; total time=   0.5s\n",
      "[CV] END ......................max_depth=13, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=13, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=13, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=13, n_estimators=50; total time=   0.4s\n",
      "[CV] END ......................max_depth=13, n_estimators=60; total time=   0.5s\n",
      "[CV] END ......................max_depth=13, n_estimators=60; total time=   0.5s\n",
      "[CV] END ......................max_depth=13, n_estimators=60; total time=   0.5s\n",
      "[CV] END ......................max_depth=13, n_estimators=60; total time=   0.5s\n",
      "[CV] END ......................max_depth=13, n_estimators=60; total time=   0.5s\n",
      "[CV] END ......................max_depth=13, n_estimators=70; total time=   0.6s\n",
      "[CV] END ......................max_depth=13, n_estimators=70; total time=   0.6s\n",
      "[CV] END ......................max_depth=13, n_estimators=70; total time=   0.6s\n",
      "[CV] END ......................max_depth=13, n_estimators=70; total time=   0.6s\n",
      "[CV] END ......................max_depth=13, n_estimators=70; total time=   0.6s\n",
      "[CV] END ......................max_depth=13, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=13, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=13, n_estimators=80; total time=   0.6s\n",
      "[CV] END ......................max_depth=13, n_estimators=80; total time=   0.7s\n",
      "[CV] END ......................max_depth=13, n_estimators=80; total time=   0.7s\n",
      "[CV] END ......................max_depth=13, n_estimators=90; total time=   0.7s\n",
      "[CV] END ......................max_depth=13, n_estimators=90; total time=   0.7s\n",
      "[CV] END ......................max_depth=13, n_estimators=90; total time=   0.7s\n",
      "[CV] END ......................max_depth=13, n_estimators=90; total time=   0.7s\n",
      "[CV] END ......................max_depth=13, n_estimators=90; total time=   0.7s\n",
      "[CV] END .....................max_depth=13, n_estimators=100; total time=   0.8s\n",
      "[CV] END .....................max_depth=13, n_estimators=100; total time=   0.8s\n",
      "[CV] END .....................max_depth=13, n_estimators=100; total time=   0.8s\n",
      "[CV] END .....................max_depth=13, n_estimators=100; total time=   0.8s\n",
      "[CV] END .....................max_depth=13, n_estimators=100; total time=   0.8s\n",
      "[CV] END .....................max_depth=13, n_estimators=110; total time=   0.9s\n",
      "[CV] END .....................max_depth=13, n_estimators=110; total time=   0.9s\n",
      "[CV] END .....................max_depth=13, n_estimators=110; total time=   0.9s\n",
      "[CV] END .....................max_depth=13, n_estimators=110; total time=   0.9s\n",
      "[CV] END .....................max_depth=13, n_estimators=110; total time=   0.9s\n",
      "[CV] END .....................max_depth=13, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=13, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=13, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=13, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=13, n_estimators=120; total time=   0.9s\n",
      "[CV] END .....................max_depth=13, n_estimators=130; total time=   1.0s\n",
      "[CV] END .....................max_depth=13, n_estimators=130; total time=   1.0s\n",
      "[CV] END .....................max_depth=13, n_estimators=130; total time=   1.1s\n",
      "[CV] END .....................max_depth=13, n_estimators=130; total time=   1.1s\n",
      "[CV] END .....................max_depth=13, n_estimators=130; total time=   1.0s\n",
      "[CV] END .....................max_depth=13, n_estimators=140; total time=   1.1s\n",
      "[CV] END .....................max_depth=13, n_estimators=140; total time=   1.1s\n",
      "[CV] END .....................max_depth=13, n_estimators=140; total time=   1.1s\n",
      "[CV] END .....................max_depth=13, n_estimators=140; total time=   1.1s\n",
      "[CV] END .....................max_depth=13, n_estimators=140; total time=   1.1s\n",
      "[CV] END .....................max_depth=13, n_estimators=150; total time=   1.2s\n",
      "[CV] END .....................max_depth=13, n_estimators=150; total time=   1.1s\n",
      "[CV] END .....................max_depth=13, n_estimators=150; total time=   1.2s\n",
      "[CV] END .....................max_depth=13, n_estimators=150; total time=   1.2s\n",
      "[CV] END .....................max_depth=13, n_estimators=150; total time=   1.2s\n",
      "[CV] END .....................max_depth=13, n_estimators=160; total time=   1.2s\n",
      "[CV] END .....................max_depth=13, n_estimators=160; total time=   1.2s\n",
      "[CV] END .....................max_depth=13, n_estimators=160; total time=   1.3s\n",
      "[CV] END .....................max_depth=13, n_estimators=160; total time=   1.2s\n",
      "[CV] END .....................max_depth=13, n_estimators=160; total time=   1.2s\n",
      "[CV] END .....................max_depth=13, n_estimators=170; total time=   1.3s\n",
      "[CV] END .....................max_depth=13, n_estimators=170; total time=   1.3s\n",
      "[CV] END .....................max_depth=13, n_estimators=170; total time=   1.3s\n",
      "[CV] END .....................max_depth=13, n_estimators=170; total time=   1.3s\n",
      "[CV] END .....................max_depth=13, n_estimators=170; total time=   1.3s\n",
      "[CV] END .....................max_depth=13, n_estimators=180; total time=   1.4s\n",
      "[CV] END .....................max_depth=13, n_estimators=180; total time=   1.4s\n",
      "[CV] END .....................max_depth=13, n_estimators=180; total time=   1.4s\n",
      "[CV] END .....................max_depth=13, n_estimators=180; total time=   1.4s\n",
      "[CV] END .....................max_depth=13, n_estimators=180; total time=   1.4s\n",
      "[CV] END .....................max_depth=13, n_estimators=190; total time=   1.5s\n",
      "[CV] END .....................max_depth=13, n_estimators=190; total time=   1.5s\n",
      "[CV] END .....................max_depth=13, n_estimators=190; total time=   1.5s\n",
      "[CV] END .....................max_depth=13, n_estimators=190; total time=   1.5s\n",
      "[CV] END .....................max_depth=13, n_estimators=190; total time=   1.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(class_weight='balanced_subsample'),\n",
       "             n_jobs=2,\n",
       "             param_grid={'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
       "                         'n_estimators': [20, 30, 40, 50, 60, 70, 80, 90, 100,\n",
       "                                          110, 120, 130, 140, 150, 160, 170,\n",
       "                                          180, 190]},\n",
       "             scoring=make_scorer(f1_score, average=macro), verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1529f797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', max_depth=7,\n",
       "                       n_estimators=40, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_final = RandomForestClassifier(random_state=0, n_estimators=rf_random.best_params_['n_estimators'], max_depth=rf_random.best_params_['max_depth'],class_weight='balanced_subsample')\n",
    "rf_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76399166",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = rf_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9a7087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0      0.000     0.000     0.000         0\n",
      "         2.0      0.444     1.000     0.615         4\n",
      "         3.0      0.611     0.478     0.537        23\n",
      "         4.0      0.476     0.588     0.526        17\n",
      "         5.0      0.000     0.000     0.000         5\n",
      "         6.0      0.667     0.583     0.622        24\n",
      "         7.0      0.500     0.183     0.268        60\n",
      "         8.0      0.466     0.680     0.553       100\n",
      "         9.0      0.343     0.343     0.343        70\n",
      "        10.0      0.308     0.400     0.348        50\n",
      "        11.0      0.333     0.176     0.231        34\n",
      "        12.0      0.571     0.308     0.400        13\n",
      "\n",
      "    accuracy                          0.430       400\n",
      "   macro avg      0.393     0.395     0.370       400\n",
      "weighted avg      0.437     0.430     0.411       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(X_pred,y_test,digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bf0da66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, X_pred)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41e0a872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, X_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa7626",
   "metadata": {},
   "source": [
    "### XGB CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e6e1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(tree_method = \"exact\", predictor = \"cpu_predictor\",\n",
    "                            objective = \"multi:softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae4fdc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "               \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "               \"max_depth\": [2, 4, 7, 10],\n",
    "               \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "               \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "               \"reg_alpha\": [0, 0.5, 1],\n",
    "               \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "               \"min_child_weight\": [1, 3, 5, 7],\n",
    "               \"n_estimators\": [100, 250, 500, 1000]}\n",
    "# subsample: Denotes the subsample ratio of columns for each split, in each level.\n",
    "# colsample_bytree: Denotes the fraction of columns to be randomly samples for each tree.\n",
    "# gamma: Gamma specifies the minimum loss reduction required to make a split.\n",
    "# reg_alpha: Lasso L1 regularization\n",
    "# reg_lambda: Ridge L2 reguralarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RandomizedSearchCV Object\n",
    "xgb_rscv = RandomizedSearchCV(xgb_clf, param_distributions = parameters, scoring = \"f1_micro\",\n",
    "                             cv = 10, verbose = 3, random_state = 40 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c24c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[15:21:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6;, score=0.525 total time=   0.7s\n",
      "[15:21:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6;, score=0.600 total time=   0.6s\n",
      "[15:21:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6;, score=0.562 total time=   0.6s\n",
      "[15:21:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6;, score=0.425 total time=   0.6s\n",
      "[15:21:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6;, score=0.550 total time=   0.6s\n",
      "[15:21:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6;, score=0.556 total time=   0.6s\n",
      "[15:21:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6;, score=0.487 total time=   0.6s\n",
      "[15:21:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6;, score=0.512 total time=   0.6s\n",
      "[15:21:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6;, score=0.569 total time=   0.6s\n",
      "[15:21:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=2, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6;, score=0.531 total time=   0.6s\n",
      "[15:21:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4;, score=0.519 total time=   0.5s\n",
      "[15:21:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4;, score=0.562 total time=   0.5s\n",
      "[15:21:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4;, score=0.581 total time=   0.5s\n",
      "[15:21:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4;, score=0.456 total time=   0.6s\n",
      "[15:21:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4;, score=0.550 total time=   0.5s\n",
      "[15:21:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4;, score=0.550 total time=   0.5s\n",
      "[15:21:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4;, score=0.500 total time=   0.5s\n",
      "[15:21:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4;, score=0.506 total time=   0.5s\n",
      "[15:21:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4;, score=0.519 total time=   0.6s\n",
      "[15:21:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=0.8, gamma=2, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=100, reg_alpha=1, reg_lambda=4.5, subsample=0.4;, score=0.525 total time=   0.6s\n",
      "[15:21:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2;, score=0.506 total time=   1.3s\n",
      "[15:21:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2;, score=0.569 total time=   1.2s\n",
      "[15:21:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2;, score=0.544 total time=   1.2s\n",
      "[15:21:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2;, score=0.438 total time=   1.2s\n",
      "[15:21:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2;, score=0.525 total time=   1.2s\n",
      "[15:21:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2;, score=0.512 total time=   1.2s\n",
      "[15:21:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2;, score=0.487 total time=   1.7s\n",
      "[15:21:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2;, score=0.481 total time=   1.3s\n",
      "[15:22:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2;, score=0.525 total time=   1.3s\n",
      "[15:22:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=250, reg_alpha=0.5, reg_lambda=4.5, subsample=0.2;, score=0.512 total time=   1.3s\n",
      "[15:22:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.494 total time=   0.9s\n",
      "[15:22:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.581 total time=   0.9s\n",
      "[15:22:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.562 total time=   0.9s\n",
      "[15:22:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.456 total time=   0.9s\n",
      "[15:22:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.544 total time=   0.9s\n",
      "[15:22:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.537 total time=   0.9s\n",
      "[15:22:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.469 total time=   0.9s\n",
      "[15:22:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.463 total time=   0.9s\n",
      "[15:22:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.500 total time=   0.9s\n",
      "[15:22:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.7;, score=0.519 total time=   0.9s\n",
      "[15:22:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5;, score=0.531 total time=   4.1s\n",
      "[15:22:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5;, score=0.588 total time=   4.6s\n",
      "[15:22:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5;, score=0.537 total time=   4.6s\n",
      "[15:22:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5;, score=0.431 total time=   4.1s\n",
      "[15:22:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5;, score=0.556 total time=   3.9s\n",
      "[15:22:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5;, score=0.512 total time=   4.1s\n",
      "[15:22:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5;, score=0.487 total time=   4.1s\n",
      "[15:22:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5;, score=0.519 total time=   4.3s\n",
      "[15:22:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5;, score=0.525 total time=   5.0s\n",
      "[15:22:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=7, n_estimators=500, reg_alpha=1, reg_lambda=4.5, subsample=0.5;, score=0.525 total time=   9.2s\n",
      "[15:23:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7;, score=0.500 total time=   0.9s\n",
      "[15:23:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7;, score=0.562 total time=   1.0s\n",
      "[15:23:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7;, score=0.581 total time=   3.0s\n",
      "[15:23:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7;, score=0.419 total time=   1.8s\n",
      "[15:23:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7;, score=0.569 total time=   2.8s\n",
      "[15:23:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7;, score=0.537 total time=   2.0s\n",
      "[15:23:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7;, score=0.469 total time=   2.0s\n",
      "[15:23:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7;, score=0.494 total time=   2.0s\n",
      "[15:23:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7;, score=0.537 total time=   1.9s\n",
      "[15:23:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=0.01, learning_rate=0.001, max_depth=10, min_child_weight=3, n_estimators=100, reg_alpha=1, reg_lambda=3, subsample=0.7;, score=0.544 total time=   1.9s\n",
      "[15:23:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7;, score=0.531 total time=   6.4s\n",
      "[15:23:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7;, score=0.575 total time=   5.4s\n",
      "[15:23:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7;, score=0.556 total time=   4.0s\n",
      "[15:23:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7;, score=0.406 total time=   3.8s\n",
      "[15:23:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7;, score=0.537 total time=   4.3s\n",
      "[15:23:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7;, score=0.512 total time=   4.8s\n",
      "[15:23:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7;, score=0.487 total time=   8.0s\n",
      "[15:23:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7;, score=0.512 total time=   4.7s\n",
      "[15:24:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7;, score=0.562 total time=   4.0s\n",
      "[15:24:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=1, subsample=0.7;, score=0.512 total time=   4.5s\n",
      "[15:24:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4;, score=0.519 total time=  18.7s\n",
      "[15:24:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4;, score=0.575 total time=  18.1s\n",
      "[15:24:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4;, score=0.575 total time=  19.0s\n",
      "[15:25:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4;, score=0.463 total time=  17.9s\n",
      "[15:25:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4;, score=0.562 total time=  23.1s\n",
      "[15:25:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4;, score=0.544 total time=  19.2s\n",
      "[15:26:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4;, score=0.494 total time=  26.0s\n",
      "[15:26:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4;, score=0.506 total time=  49.4s\n",
      "[15:27:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4;, score=0.544 total time=  19.4s\n",
      "[15:27:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=1.5, subsample=0.4;, score=0.512 total time=  25.6s\n",
      "[15:28:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7;, score=0.537 total time=  16.5s\n",
      "[15:28:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7;, score=0.619 total time=  17.4s\n",
      "[15:28:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7;, score=0.550 total time=   7.3s\n",
      "[15:28:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7;, score=0.438 total time=   5.6s\n",
      "[15:28:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7;, score=0.544 total time=   5.9s\n",
      "[15:28:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7;, score=0.531 total time=   6.6s\n",
      "[15:29:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7;, score=0.463 total time=   7.6s\n",
      "[15:29:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7;, score=0.519 total time=   7.1s\n",
      "[15:29:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7;, score=0.544 total time=   6.1s\n",
      "[15:29:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=3, subsample=0.7;, score=0.506 total time=   8.7s\n",
      "[15:29:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4;, score=0.487 total time=   3.7s\n",
      "[15:29:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4;, score=0.550 total time=   3.9s\n",
      "[15:29:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4;, score=0.556 total time=   3.9s\n",
      "[15:29:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4;, score=0.438 total time=   3.2s\n",
      "[15:29:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4;, score=0.544 total time=   3.5s\n",
      "[15:29:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 6/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4;, score=0.512 total time=   4.8s\n",
      "[15:29:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 7/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4;, score=0.469 total time=   3.2s\n",
      "[15:30:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 8/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4;, score=0.506 total time=   3.3s\n",
      "[15:30:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 9/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4;, score=0.512 total time=   3.5s\n",
      "[15:30:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 10/10] END colsample_bytree=0.6, gamma=2, learning_rate=0.001, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.5, reg_lambda=2, subsample=0.4;, score=0.512 total time=   3.5s\n",
      "[15:30:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "model_xgboost = xgb_rscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60e6cbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1.0,\n",
       "              enable_categorical=False, gamma=1.5, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=0.6,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_final = XGBClassifier(random_state=0, \n",
    "                          n_estimators=xgb_rscv.best_params_['n_estimators'], \n",
    "                          max_depth=xgb_rscv.best_params_['max_depth'],\n",
    "                          learning_rate=xgb_rscv.best_params_['learning_rate'],\n",
    "                          gamma=xgb_rscv.best_params_['gamma'],\n",
    "                          colsample_bytree=xgb_rscv.best_params_['colsample_bytree'],\n",
    "                          subsample=xgb_rscv.best_params_['subsample'],\n",
    "                          reg_alpha=xgb_rscv.best_params_['reg_alpha'],\n",
    "                          reg_lambda=xgb_rscv.best_params_['reg_lambda'],\n",
    "                          min_child_weight=xgb_rscv.best_params_['min_child_weight'])\n",
    "xgb_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07011f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acf44109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0      0.000     0.000     0.000         0\n",
      "         2.0      0.222     1.000     0.364         2\n",
      "         3.0      0.556     0.476     0.513        21\n",
      "         4.0      0.667     0.636     0.651        22\n",
      "         5.0      0.000     0.000     0.000         4\n",
      "         6.0      0.667     0.560     0.609        25\n",
      "         7.0      0.136     0.333     0.194         9\n",
      "         8.0      0.822     0.670     0.738       179\n",
      "         9.0      0.300     0.477     0.368        44\n",
      "        10.0      0.523     0.430     0.472        79\n",
      "        11.0      0.111     0.222     0.148         9\n",
      "        12.0      0.000     0.000     0.000         6\n",
      "\n",
      "    accuracy                          0.550       400\n",
      "   macro avg      0.334     0.401     0.338       400\n",
      "weighted avg      0.618     0.550     0.575       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_pred,y_test,digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5e798a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm1 = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0ffb871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016bd82f",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c28a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_Train = sc_X.fit_transform(X_train)\n",
    "X_Test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3de852fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_Train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d192ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Pred = classifier.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a51a888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm2 = confusion_matrix(y_test, Y_Pred)\n",
    "sns.heatmap(cm2, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2da8a219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5525"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, Y_Pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62dae5",
   "metadata": {},
   "source": [
    "### Extreme Learning Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0dc0c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d59e4a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73fd94bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination is:  0.7369488832700415\n",
      "Model intercept:  33.53288664556456\n",
      "Slope:  [ 2.90855818e-03  2.89946073e-02  2.44161928e-01  1.56844115e-02\n",
      " -5.83864978e+00  2.13070420e+00 -2.76824506e+00 -2.04338533e+00\n",
      "  2.02230344e+00 -3.24136844e+01 -2.69200715e+01 -2.84116648e+01\n",
      " -3.09393402e+01]\n"
     ]
    }
   ],
   "source": [
    "    r_sq = model.score(X_train, y_train)\n",
    "    print('Coefficient of determination is: ', r_sq)\n",
    "    print('Model intercept: ', model.intercept_)\n",
    "    print(\"Slope: \", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "394484f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:  [8, 9, 7, 8, 8, 7, 8, 7, 4, 4, 8, 7, 8, 8, 7, 2, 5, 4, 6, 9, 1, 9, 8, 6, 8, 10, 8, 7, 7, 6, 8, 9, 5, 7, 7, 10, 10, 9, 9, 9, 9, 10, 8, 8, 8, 9, 11, 9, 6, 8, 8, 8, 10, 9, 9, 9, 8, 4, 9, 8, 9, 8, 9, 8, 9, 10, 7, 9, 9, 8, 9, 6, 5, 6, 7, 9, 10, 9, 8, 7, 7, 8, 7, 9, 10, 9, 7, 9, 10, 9, 9, 10, 8, 10, 10, 3, 4, 7, 3, 9, 5, 6, 9, 9, 8, 8, 9, 11, 7, 7, 7, 3, 9, 7, 7, 7, 3, 9, 5, 8, 9, 9, 8, 9, 7, 9, 8, 7, 9, 7, 9, 6, 7, 8, 5, 7, 8, 8, 7, 5, 7, 11, 10, 9, 9, 7, 9, 10, 4, 2, 9, 1, 9, 9, 10, 8, 8, 6, 6, 7, 1, 6, 8, 6, 3, 9, 7, 4, 7, 6, 9, 7, 6, 7, 7, 1, 8, 8, 3, 9, 8, 8, 5, 8, 7, 10, 8, 8, 9, 2, 7, 9, 6, 8, 8, 7, 5, 8, 8, 9, 8, 7, 7, 7, 7, 4, 8, 9, 6, 7, 8, 7, 7, 7, 7, 9, 10, 8, 7, 7, 10, 9, 10, 8, 6, 10, 7, 3, 9, 6, 8, 8, 6, 7, 8, 9, 7, 6, 9, 10, 7, 5, 7, 7, 7, 11, 8, 7, 10, 8, 1, 9, 8, 8, 5, 6, 4, 7, 7, 7, 5, 6, 7, 7, 9, 9, 8, 3, 9, 1, 5, 9, 8, 9, 8, 8, 8, 8, 8, 7, 8, 9, 9, 7, 9, 6, 7, 8, 7, 10, 9, 7, 8, 8, 6, 7, 9, 8, 6, 6, 6, 9, 9, 7, 9, 6, 7, 8, 8, 8, 7, 9, 8, 6, 7, 7, 7, 8, 7, 9, 10, 7, 7, 8, 9, 6, 8, 8, 8, 11, 10, 9, 8, 8, 10, 10, 8, 8, 7, 9, 3, 7, 6, 6, 10, 4, 8, 6, 7, 9, 7, 6, 6, 7, 8, 9, 5, 1, 9, 7, 8, 8, 8, 8, 8, 6, 6, 7, 8, 8, 8, 6, 7, 7, 8, 6, 6, 7, 11, 8, 9, 5, 8, 10, 6, 8, 7, 5, 10, 7, 7, 7, 5, 7, 10, 6, 7, 0, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "y_pred = list(map(int, model.predict(X_test)))\n",
    "print(\"Predicted values: \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c44b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 1.3387\n",
      "Variance score: 0.7219\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error: %.4f\" % np.mean((model.predict(X_test) - y_test) ** 2))\n",
    "print('Variance score: %.4f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024f4b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
